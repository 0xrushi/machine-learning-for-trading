{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and store STOOQ data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains information on downloading the STOOQ stock and ETF price data that we use in [Chapter 09](../09_time_series_models) for a pairs trading strategy based on cointegration and [Chapter 11](../11_decision_trees_random_forests) for a long-short strategy using Random Forest return predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T14:32:07.092623Z",
     "start_time": "2020-06-18T14:32:07.090885Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T14:32:07.263130Z",
     "start_time": "2020-06-18T14:32:07.259861Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile, BadZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Data Store path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the path to the `DATA_STORE` if you would like to store the data elsewhere and change the notebooks accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T02:27:54.832609Z",
     "start_time": "2020-06-19T02:27:54.824778Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_STORE = Path('assets.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stooq Historical Market Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that the below downloading details may change at any time as Stooq updates their website; if you encounter errors, please inspect their website and raise a GitHub issue to let us know so we can update the information.\n",
    "\n",
    "> Update 12/2020: please note that STOOQ will disable automatic downloads and require CAPTCHA starting Dec 10, 2020 so that the code that downloads and unpacks the zip files will no longer work; please navigate to their website [here](https://stooq.com/db/h/) for manual download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download price data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download **price data** for the selected combination of asset class, market and frequency from [the Stooq website](https://stooq.com/db/h/)\n",
    "2. Store the result under `stooq` using the preferred folder structure outlined on the website. It has the structure: `/data/freq/market/asset_class`, such as `/data/daily/us/nasdaq etfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T02:17:23.456087Z",
     "start_time": "2020-06-19T02:17:23.449798Z"
    }
   },
   "outputs": [],
   "source": [
    "stooq_path = Path('stooq') \n",
    "if not stooq_path.exists():\n",
    "    stooq_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the symbol for the market you want to download price data for. In this book we'll be useing `us` and `jp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T02:17:26.841192Z",
     "start_time": "2020-06-19T02:17:26.835288Z"
    }
   },
   "outputs": [],
   "source": [
    "STOOQ_URL = 'https://static.stooq.com/db/h/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T02:23:15.379159Z",
     "start_time": "2020-06-19T02:23:01.883773Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_price_data(market='us'):\n",
    "    data_url = f'd_{market}_txt.zip'\n",
    "    response = requests.get(STOOQ_URL + data_url).content\n",
    "    with ZipFile(BytesIO(response)) as zip_file:\n",
    "        for i, file in enumerate(zip_file.namelist()):\n",
    "            if not file.endswith('.txt'):\n",
    "                continue\n",
    "            local_file = stooq_path / file\n",
    "            local_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "            with local_file.open('wb') as output:\n",
    "                for line in zip_file.open(file).readlines():\n",
    "                    output.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T02:17:23.882490Z",
     "start_time": "2020-06-19T02:17:23.879665Z"
    }
   },
   "outputs": [],
   "source": [
    "# for market in ['us', 'jp']:\n",
    "#     download_price_data(market=market)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T20:43:47.976210Z",
     "start_time": "2020-04-18T20:43:47.968770Z"
    }
   },
   "source": [
    "Add the corresponding **symbols**, i.e., tickers and names by following the directory tree on the same site. You can also adapt the following code snippet using the appropriate asset code that you find by inspecting the url; this example works for NASDAQ ETFs that have code `g=69`:\n",
    "```python\n",
    "df = pd.read_csv('https://stooq.com/db/l/?g=69', sep='        ').apply(lambda x: x.str.strip())\n",
    "df.columns = ['ticker', 'name']\n",
    "df.drop_duplicates('ticker').to_csv('stooq/data/tickers/us/nasdaq etfs.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T01:30:28.894603Z",
     "start_time": "2020-06-19T01:30:28.885132Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata_dict = {\n",
    "    ('jp', 'tse etfs'): 34,\n",
    "    ('jp', 'tse stocks'): 32,\n",
    "    ('us', 'nasdaq etfs'): 69,\n",
    "    ('us', 'nasdaq stocks'): 27,\n",
    "    ('us', 'nyse etfs'): 70,\n",
    "    ('us', 'nyse stocks'): 28,\n",
    "    ('us', 'nysemkt stocks'): 26\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T01:36:26.300430Z",
     "start_time": "2020-06-19T01:36:22.212007Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4t/lib/python3.10/site-packages/pandas/io/parsers/python_parser.py:382\u001b[0m, in \u001b[0;36mPythonParser._infer_columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffered_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_pos \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m hr:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4t/lib/python3.10/site-packages/pandas/io/parsers/python_parser.py:620\u001b[0m, in \u001b[0;36mPythonParser._buffered_line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4t/lib/python3.10/site-packages/pandas/io/parsers/python_parser.py:722\u001b[0m, in \u001b[0;36mPythonParser._next_line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 722\u001b[0m     orig_line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_iter_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4t/lib/python3.10/site-packages/pandas/io/parsers/python_parser.py:786\u001b[0m, in \u001b[0;36mPythonParser._next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (market, asset_class), code \u001b[38;5;129;01min\u001b[39;00m metadata_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 2\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://stooq.com/db/l/?g=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m      3\u001b[0m     df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop_duplicates(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4t/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4t/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4t/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4t/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4t/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4t/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4t/lib/python3.10/site-packages/pandas/io/parsers/python_parser.py:122\u001b[0m, in \u001b[0;36mPythonParser.__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_col_indices: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m columns: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]]\n\u001b[1;32m    118\u001b[0m (\n\u001b[1;32m    119\u001b[0m     columns,\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_original_columns,\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols,\n\u001b[0;32m--> 122\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Now self.columns has the set of columns that we will process.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# The original set is stored in self.original_columns.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'index_names'\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns: \u001b[38;5;28mlist\u001b[39m[Hashable]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml4t/lib/python3.10/site-packages/pandas/io/parsers/python_parser.py:410\u001b[0m, in \u001b[0;36mPythonParser._infer_columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m columns, num_original_columns, unnamed_cols\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames:\n\u001b[0;32m--> 410\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m EmptyDataError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo columns to parse from file\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames[:]\n\u001b[1;32m    414\u001b[0m this_columns: \u001b[38;5;28mlist\u001b[39m[Scalar \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "for (market, asset_class), code in metadata_dict.items():\n",
    "    df = pd.read_csv(f'https://stooq.com/db/l/?g={code}', sep='        ').apply(lambda x: x.str.strip())\n",
    "    df.columns = ['ticker', 'name']\n",
    "    df = df.drop_duplicates('ticker').dropna()\n",
    "    print(market, asset_class, f'# tickers: {df.shape[0]:,.0f}')\n",
    "    path = stooq_path / 'tickers' / market\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True)\n",
    "    df.to_csv(path / f'{asset_class}.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jp tse etfs # tickers: 398\n",
      "jp tse stocks # tickers: 3,883\n",
      "us nasdaq etfs # tickers: 353\n",
      "us nasdaq stocks # tickers: 4,628\n",
      "us nyse etfs # tickers: 2,862\n",
      "us nyse stocks # tickers: 3,021\n",
      "us nysemkt stocks # tickers: 324\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for (market, asset_class), code in metadata_dict.items():\n",
    "    date_file = os.path.join(\"./stooq\", f'{code}.txt')\n",
    "    df = pd.read_csv(date_file, sep='        ').apply(lambda x: x.str.strip())\n",
    "    df.columns = ['ticker', 'name']\n",
    "    df = df.drop_duplicates('ticker').dropna()\n",
    "    print(market, asset_class, f'# tickers: {df.shape[0]:,.0f}')\n",
    "    path = stooq_path / 'tickers' / market\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True)\n",
    "    df.to_csv(path / f'{asset_class}.csv', index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store price data in HDF5 format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up loading, we store the price data in HDF format. The function `get_stooq_prices_and_symbols` loads data assuming the directory structure described above and takes the following arguments:\n",
    "- frequency (see Stooq website for options as these may change; default is `daily`\n",
    "- market (default: `us`), and \n",
    "- asset class (default: `nasdaq etfs`.\n",
    "\n",
    "It removes files that do not have data or do not appear in the corresponding list of symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T02:28:05.958722Z",
     "start_time": "2020-06-19T02:28:05.940267Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_stooq_prices_and_tickers(frequency='daily',\n",
    "                                 market='us',\n",
    "                                 asset_class='nasdaq etfs'):\n",
    "    prices = []\n",
    "    \n",
    "    tickers = (pd.read_csv(stooq_path / 'tickers' / market / f'{asset_class}.csv'))\n",
    "\n",
    "    if frequency in ['5 min', 'hourly']:\n",
    "        parse_dates = [['date', 'time']]\n",
    "        date_label = 'date_time'\n",
    "    else:\n",
    "        parse_dates = ['date']\n",
    "        date_label = 'date'\n",
    "    names = ['ticker', 'freq', 'date', 'time', \n",
    "             'open', 'high', 'low', 'close','volume', 'openint']\n",
    "    \n",
    "    usecols = ['ticker', 'open', 'high', 'low', 'close', 'volume'] + parse_dates\n",
    "    path = stooq_path / 'data' / frequency / market / asset_class\n",
    "    print(path.as_posix())\n",
    "    files = path.glob('**/*.txt')\n",
    "    for i, file in enumerate(files, 1):\n",
    "        if i % 500 == 0:\n",
    "            print(i)\n",
    "        if file.stem not in set(tickers.ticker.str.lower()):\n",
    "            print(file.stem, 'not available')\n",
    "            file.unlink()\n",
    "        else:\n",
    "            try:\n",
    "                df = (pd.read_csv(\n",
    "                    file,\n",
    "                    names=names,\n",
    "                    usecols=usecols,\n",
    "                    header=0,\n",
    "                    parse_dates=parse_dates))\n",
    "                prices.append(df)\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print('\\tdata missing', file.stem)\n",
    "                file.unlink()\n",
    "\n",
    "    prices = (pd.concat(prices, ignore_index=True)\n",
    "              .rename(columns=str.lower)\n",
    "              .set_index(['ticker', date_label])\n",
    "              .apply(lambda x: pd.to_numeric(x, errors='coerce')))\n",
    "    return prices, tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using US equities and ETFs in [Chapter 9](../09_time_series_models) and and Japanese equities in [Chapter 11](../11_decision_trees_random_forests). The following code collects the price data for the period 2000-2019 and stores it with the corresponding symbols in the global `assets.h5` store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T02:30:25.079270Z",
     "start_time": "2020-06-19T02:28:06.594886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tse stocks\n",
      "stooq/data/daily/jp/tse stocks\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "1301.jp-checkpoint not available\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "9919.jp not available\n",
      "\n",
      "No. of observations per asset\n",
      "count    3370.000000\n",
      "mean     2821.248961\n",
      "std      1174.196448\n",
      "min         1.000000\n",
      "25%      2176.500000\n",
      "50%      3052.000000\n",
      "75%      3621.000000\n",
      "max      4905.000000\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9507609 entries, ('1301.JP', Timestamp('2005-03-22 00:00:00')) to ('9997.JP', Timestamp('2019-12-30 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   open    9507609 non-null  float64\n",
      " 1   high    9507609 non-null  float64\n",
      " 2   low     9507609 non-null  float64\n",
      " 3   close   9507609 non-null  float64\n",
      " 4   volume  9507609 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 399.3+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3883 entries, 0 to 3882\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ticker  3883 non-null   object\n",
      " 1   name    3883 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 60.8+ KB\n",
      "None\n",
      "\n",
      "nasdaq etfs\n",
      "stooq/data/daily/us/nasdaq etfs\n",
      "\n",
      "No. of observations per asset\n",
      "count     317.000000\n",
      "mean     1684.321767\n",
      "std      1129.105234\n",
      "min         2.000000\n",
      "25%       666.000000\n",
      "50%      1545.000000\n",
      "75%      2538.000000\n",
      "max      5031.000000\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 533930 entries, ('AADR.US', Timestamp('2010-07-21 00:00:00')) to ('YLDE.US', Timestamp('2019-12-27 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   open    533930 non-null  float64\n",
      " 1   high    533930 non-null  float64\n",
      " 2   low     533930 non-null  float64\n",
      " 3   close   533930 non-null  float64\n",
      " 4   volume  533930 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 22.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 353 entries, 0 to 352\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ticker  353 non-null    object\n",
      " 1   name    353 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 5.6+ KB\n",
      "None\n",
      "\n",
      "nasdaq stocks\n",
      "stooq/data/daily/us/nasdaq stocks\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "slnaw.us not available\n",
      "3500\n",
      "pltnr.us not available\n",
      "lgvcu.us not available\n",
      "4000\n",
      "4500\n",
      "\n",
      "No. of observations per asset\n",
      "count    2199.000000\n",
      "mean     2238.140518\n",
      "std      1511.665797\n",
      "min         2.000000\n",
      "25%       697.000000\n",
      "50%      2213.000000\n",
      "75%      3737.000000\n",
      "max      5031.000000\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 4921671 entries, ('AACG.US', Timestamp('2008-01-28 00:00:00')) to ('ZYXI.US', Timestamp('2019-12-31 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   open    4921671 non-null  float64\n",
      " 1   high    4921671 non-null  float64\n",
      " 2   low     4921671 non-null  float64\n",
      " 3   close   4921671 non-null  float64\n",
      " 4   volume  4921671 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 206.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4628 entries, 0 to 4627\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ticker  4628 non-null   object\n",
      " 1   name    4628 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 72.4+ KB\n",
      "None\n",
      "\n",
      "nyse etfs\n",
      "stooq/data/daily/us/nyse etfs\n",
      "500\n",
      "1000\n",
      "1500\n",
      "gdef.us not available\n",
      "2000\n",
      "2500\n",
      "\n",
      "No. of observations per asset\n",
      "count    1474.000000\n",
      "mean     1800.772049\n",
      "std      1264.817082\n",
      "min         1.000000\n",
      "25%       564.500000\n",
      "50%      1662.500000\n",
      "75%      3055.750000\n",
      "max      3738.000000\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 2654338 entries, ('AAAU.US', Timestamp('2018-08-15 00:00:00')) to ('ZSL.US', Timestamp('2019-12-31 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   open    2654338 non-null  float64\n",
      " 1   high    2654338 non-null  float64\n",
      " 2   low     2654338 non-null  float64\n",
      " 3   close   2654338 non-null  float64\n",
      " 4   volume  2654338 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 111.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2862 entries, 0 to 2861\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ticker  2862 non-null   object\n",
      " 1   name    2862 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 44.8+ KB\n",
      "None\n",
      "\n",
      "nyse stocks\n",
      "stooq/data/daily/us/nyse stocks\n",
      "graf-u.us not available\n",
      "cubi_e.us not available\n",
      "mrdb-ws.us not available\n",
      "chmi_a.us not available\n",
      "kcgi-ws.us not available\n",
      "cmre_c.us not available\n",
      "hipo-ws.us not available\n",
      "kref_a.us not available\n",
      "dna-ws.us not available\n",
      "hfro_a.us not available\n",
      "grbk_a.us not available\n",
      "bark-ws.us not available\n",
      "mitt_b.us not available\n",
      "evex-ws.us not available\n",
      "frey-ws.us not available\n",
      "evtl-ws.us not available\n",
      "grnd-ws.us not available\n",
      "500\n",
      "clbr-ws.us not available\n",
      "banc_f.us not available\n",
      "bfac-ws.us not available\n",
      "cmre_e.us not available\n",
      "nfys-u.us not available\n",
      "hyac-u.us not available\n",
      "ionq-ws.us not available\n",
      "bkkt-ws.us not available\n",
      "glog_a.us not available\n",
      "cnda-u.us not available\n",
      "hyac-ws.us not available\n",
      "flme-u.us not available\n",
      "alur-ws.us not available\n",
      "cade_a.us not available\n",
      "dbrg_i.us not available\n",
      "lvwr-ws.us not available\n",
      "argo_a.us not available\n",
      "cheb-u.us not available\n",
      "clbr-u.us not available\n",
      "dlng_a.us not available\n",
      "codi_b.us not available\n",
      "glop_b.us not available\n",
      "1000\n",
      "cmre_b.us not available\n",
      "bfac-u.us not available\n",
      "lzm-ws.us not available\n",
      "mntn-u.us not available\n",
      "mitt_a.us not available\n",
      "aeva-ws.us not available\n",
      "bksy-ws.us not available\n",
      "aact-u.us not available\n",
      "kcgi-u.us not available\n",
      "cve-ws.us not available\n",
      "gwh-ws.us not available\n",
      "gmre_a.us not available\n",
      "irs-ws.us not available\n",
      "dsx-ws.us not available\n",
      "cubi_f.us not available\n",
      "ampx-ws.us not available\n",
      "hlly-ws.us not available\n",
      "cldt_a.us not available\n",
      "chmi_b.us not available\n",
      "cwen-a.us not available\n",
      "bfly-ws.us not available\n",
      "mitt_c.us not available\n",
      "1500\n",
      "dbrg_h.us not available\n",
      "gcts-ws.us not available\n",
      "llap-ws.us not available\n",
      "iipr_a.us not available\n",
      "gpmt_a.us not available\n",
      "aact-ws.us not available\n",
      "bbai-ws.us not available\n",
      "joby-ws.us not available\n",
      "ggtr-w.us not available\n",
      "etwo-ws.us not available\n",
      "gtls_b.us not available\n",
      "atco_d.us not available\n",
      "altg_a.us not available\n",
      "atco_h.us not available\n",
      "fbrt_e.us not available\n",
      "ifin-u.us not available\n",
      "codi_a.us not available\n",
      "glop_a.us not available\n",
      "clvt_a.us not available\n",
      "celg-r.us not available\n",
      "cmre_d.us not available\n",
      "mntn-ws.us not available\n",
      "dlng_b.us not available\n",
      "mkfg-ws.us not available\n",
      "codi_c.us not available\n",
      "glop_c.us not available\n",
      "ne-ws-a.us not available\n",
      "apca-u.us not available\n",
      "bnre-a.us not available\n",
      "achr-ws.us not available\n",
      "ambp-ws.us not available\n",
      "dbrg_j.us not available\n",
      "lev-ws.us not available\n",
      "2000\n",
      "vhai-ws-b.us not available\n",
      "prif_j.us not available\n",
      "prif_f.us not available\n",
      "ses-ws.us not available\n",
      "nycb_u.us not available\n",
      "trtn_a.us not available\n",
      "nycb_a.us not available\n",
      "nref_a.us not available\n",
      "ritm_d.us not available\n",
      "trtn_c.us not available\n",
      "trtl-u.us not available\n",
      "rexr_c.us not available\n",
      "prif_d.us not available\n",
      "rcfa-u.us not available\n",
      "prif_h.us not available\n",
      "rbot-ws.us not available\n",
      "voya_b.us not available\n",
      "nxgr-w.us not available\n",
      "nxdt_a.us not available\n",
      "prif_l.us not available\n",
      "sst-ws.us not available\n",
      "oust-ws.us not available\n",
      "vln-ws.us not available\n",
      "opfi-ws.us not available\n",
      "psfe-ws.us not available\n",
      "sbxc-ws.us not available\n",
      "rrac-ws.us not available\n",
      "phyt-u.us not available\n",
      "2500\n",
      "smr-ws.us not available\n",
      "spnt_b.us not available\n",
      "seal_b.us not available\n",
      "trtn_e.us not available\n",
      "ritm_b.us not available\n",
      "splp_a.us not available\n",
      "tris-ws.us not available\n",
      "soc-ws.us not available\n",
      "prif_k.us not available\n",
      "prif_g.us not available\n",
      "note-ws.us not available\n",
      "schw_j.us not available\n",
      "wnnr-u.us not available\n",
      "prif_i.us not available\n",
      "sitc_a.us not available\n",
      "sbxc-u.us not available\n",
      "rdw-ws.us not available\n",
      "rexr_b.us not available\n",
      "xflt_a.us not available\n",
      "schw_d.us not available\n",
      "vhai-ws-a.us not available\n",
      "trtx_c.us not available\n",
      "rrac-u.us not available\n",
      "trtn_b.us not available\n",
      "uhal-b.us not available\n",
      "tcoa-u.us not available\n",
      "pnst-ws.us not available\n",
      "val-ws.us not available\n",
      "seda-u.us not available\n",
      "seal_a.us not available\n",
      "3000\n",
      "qbts-ws.us not available\n",
      "ritm_a.us not available\n",
      "wbx-ws.us not available\n",
      "uwmc-ws.us not available\n",
      "psec_a.us not available\n",
      "ritm_c.us not available\n",
      "trtn_d.us not available\n",
      "npwr-ws.us not available\n",
      "tris-u.us not available\n",
      "psqh-ws.us not available\n",
      "oxy-ws.us not available\n",
      "\n",
      "No. of observations per asset\n",
      "count    2166.000000\n",
      "mean     2781.495845\n",
      "std      1500.039717\n",
      "min         2.000000\n",
      "25%      1439.000000\n",
      "50%      3729.000000\n",
      "75%      3737.000000\n",
      "max      5031.000000\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 6024720 entries, ('A.US', Timestamp('2000-01-03 00:00:00')) to ('ZXIET.US', Timestamp('2019-12-31 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   open    6024720 non-null  float64\n",
      " 1   high    6024720 non-null  float64\n",
      " 2   low     6024720 non-null  float64\n",
      " 3   close   6024720 non-null  float64\n",
      " 4   volume  6024720 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 253.1+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3021 entries, 0 to 3020\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ticker  3021 non-null   object\n",
      " 1   name    3021 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 47.3+ KB\n",
      "None\n",
      "\n",
      "nysemkt stocks\n",
      "stooq/data/daily/us/nysemkt stocks\n",
      "cnda-ws.us not available\n",
      "atek-ws.us not available\n",
      "ault_d.us not available\n",
      "ycbd_a.us not available\n",
      "adrt-u.us not available\n",
      "sach_a.us not available\n",
      "blua-u.us not available\n",
      "lgl-ws.us not available\n",
      "cheb-ws.us not available\n",
      "soar-ws.us not available\n",
      "jwsm-ws.us not available\n",
      "oust-ws-a.us not available\n",
      "cldi-ws.us not available\n",
      "legt-u.us not available\n",
      "atek-u.us not available\n",
      "lmnd-ws.us not available\n",
      "vcxb-ws.us not available\n",
      "hnra-ws.us not available\n",
      "flyx-ws.us not available\n",
      "phge-u.us not available\n",
      "legt-ws.us not available\n",
      "ambi-ws.us not available\n",
      "bite-u.us not available\n",
      "slnd-ws.us not available\n",
      "jwsm-u.us not available\n",
      "tdw-ws.us not available\n",
      "vhaq-u.us not available\n",
      "skyh-ws.us not available\n",
      "dmyy-u.us not available\n",
      "bmtx-ws.us not available\n",
      "\n",
      "No. of observations per asset\n",
      "count     212.000000\n",
      "mean     2687.047170\n",
      "std      1271.846353\n",
      "min         4.000000\n",
      "25%      1615.750000\n",
      "50%      3373.500000\n",
      "75%      3728.250000\n",
      "max      5029.000000\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 569654 entries, ('ACU.US', Timestamp('2005-02-25 00:00:00')) to ('ZOM.US', Timestamp('2019-12-31 00:00:00'))\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   open    569654 non-null  float64\n",
      " 1   high    569654 non-null  float64\n",
      " 2   low     569654 non-null  float64\n",
      " 3   close   569654 non-null  float64\n",
      " 4   volume  569654 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 24.1+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 324 entries, 0 to 323\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ticker  324 non-null    object\n",
      " 1   name    324 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 5.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load some Japanese and all US assets for 2000-2019\n",
    "markets = {'jp': ['tse stocks'],\n",
    "           'us': ['nasdaq etfs', 'nasdaq stocks', 'nyse etfs', 'nyse stocks', 'nysemkt stocks']\n",
    "          }\n",
    "frequency = 'daily'\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "for market, asset_classes in markets.items():\n",
    "    for asset_class in asset_classes:\n",
    "        print(f'\\n{asset_class}')\n",
    "        prices, tickers = get_stooq_prices_and_tickers(frequency=frequency, \n",
    "                                                       market=market, \n",
    "                                                       asset_class=asset_class)\n",
    "        \n",
    "        prices = prices.sort_index().loc[idx[:, '2000': '2019'], :]\n",
    "        names = prices.index.names\n",
    "        prices = (prices\n",
    "                  .reset_index()\n",
    "                  .drop_duplicates()\n",
    "                  .set_index(names)\n",
    "                  .sort_index())\n",
    "        \n",
    "        print('\\nNo. of observations per asset')\n",
    "        print(prices.groupby('ticker').size().describe())\n",
    "        key = f'stooq/{market}/{asset_class.replace(\" \", \"/\")}/'\n",
    "        \n",
    "        print(prices.info(null_counts=True))\n",
    "        \n",
    "        prices.to_hdf(DATA_STORE, key + 'prices', format='t')\n",
    "        \n",
    "        print(tickers.info())\n",
    "        tickers.to_hdf(DATA_STORE, key + 'tickers', format='t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bread/Documents/machine-learning-for-trading/data\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
